from sage.all import binomial, ZZ

# ---------- Utilities ----------
def N_forms(nP, deg):
    """Number of homogeneous degree=deg forms in P^nP: dim H^0(P^nP, O(deg))."""
    if deg < 0:
        return 0
    return binomial(nP + deg, nP)

def fmt_int(x):
    x = int(x)
    s = f"{x:,}"
    return s

# ---------- Demand: exact primitive diagonal via Milnor/Jacobian ring ----------
def milnor_degree_dim(n_vars, d, k):
    """
    dim of degree-k part of the Milnor ring for a smooth degree-d hypersurface in P^{n_vars-1}.
    Hilbert series: ((1 - t^{d-1})^{n_vars}) / ((1 - t)^{n_vars})
    Coeff at t^k = sum_{j>=0} (-1)^j * C(n_vars,j) * C(n_vars + (k - j*(d-1)) - 1, n_vars - 1).
    """
    if k < 0:
        return 0
    N = int(n_vars)
    s = ZZ(0)
    jmax = min(N, k // (d - 1)) if d > 1 else 0
    for j in range(jmax + 1):
        r = k - j * (d - 1)
        if r < 0:
            continue
        s += ((-1) ** j) * binomial(N, j) * binomial(N + r - 1, N - 1)
    return ZZ(s)

def hodge_hypersurface_numbers(n, d):
    """
    Hodge numbers h^{p,q} for a smooth hypersurface of degree d in P^n (complex), dimension m=n-1.
    Uses Griffiths' formula via the Milnor ring; scheme-free.
    """
    n = int(n); d = int(d)
    if n < 2 or d < 2:
        raise ValueError("Require n>=2 and d>=2.")
    m = n - 1
    n_vars = n + 1

    H = {(p, q): 0 for p in range(m + 1) for q in range(m + 1)}
    # Ambient diagonal (Lefschetz): 1 on each (p,p); primitive adds on middle p+q=m
    for p in range(m + 1):
        H[(p, p)] = 1

    prim_middle = {}
    max_deg = n_vars * (d - 2) if d >= 2 else 0
    for p in range(m + 1):
        q = m - p
        k = (p + 1) * d - (n + 1)
        dimR = milnor_degree_dim(n_vars, d, k) if 0 <= k <= max_deg else 0
        prim_middle[(p, q)] = int(dimR)
        H[(p, q)] += int(dimR)
    return {'n': n, 'm': m, 'd': d, 'H': H, 'primitive_middle': prim_middle}

def primitive_diagonal_gap(n, d):
    """
    For even-dimensional X (m even), returns the primitive diagonal gap at (p,p), p=m/2:
      gap = dim H^{p,p}_prim = Milnor-dim at k=((p+1)d - (n+1))
    total_hpp = 1 + gap (the ambient 1 plus primitive).
    """
    data = hodge_hypersurface_numbers(n, d)
    m = data['m']
    if m % 2 != 0:
        return {'n': n, 'd': d, 'm': m, 'gap': 0, 'note': 'odd m'}
    p0 = m // 2
    gap = int(data['primitive_middle'][(p0, p0)])
    total = int(data['H'][(p0, p0)])
    return {'n': n, 'd': d, 'm': m, 'p': p0, 'q': p0, 'gap': gap, 'total_hpp': total}

# ---------- Supply proxies: incidence/parameter-count (no schemes) ----------
def expected_fano_kplanes_dim(n, d, k):
    """
    Expected dimension of the Fano variety of k-planes P^k contained in a degree-d hypersurface in P^n:
      dim Gr(k, n) - number of conditions
    where number of conditions = N_forms(k, d) = binomial(d + k, k)
    dim Gr(k, n) = (k+1)(n - k)
    If negative ⇒ generically empty.
    """
    return (k + 1) * (n - k) - N_forms(k, d)

def expected_family_dim_p_fold_as_hypersurface_in_Pp1(n, p, s):
    """
    Family dimension for p-folds that are degree-s hypersurfaces in some linear P^{p+1} ⊂ P^n:
      choose P^{p+1} (Grassmann): (p+2)(n - p - 1)
      choose hypersurface of degree s in P^{p+1}: N_forms(p+1, s) - 1 (projective)
    """
    return (p + 2) * (n - p - 1) + (N_forms(p + 1, s) - 1)

def h0_on_pfold_hypersurface_in_Pp1(d, p, s):
    """
    h^0(O_Y(d)) for Y a degree-s hypersurface in P^{p+1}:
      0 → O_{P^{p+1}}(d-s) → O_{P^{p+1}}(d) → O_Y(d) → 0
      ⇒ h^0(O_Y(d)) = N_forms(p+1, d) - N_forms(p+1, d - s) (if d>=s; otherwise N_forms(p+1,d))
    """
    if d >= s:
        return N_forms(p + 1, d) - N_forms(p + 1, d - s)
    else:
        return N_forms(p + 1, d)

def supply_proxies(n, d):
    """
    Compute simple, non-circular 'supply' proxies for p-dimensional algebraic subvarieties generically contained in X_d ⊂ P^n,
    aiming at codimension p cycles on even-dimensional X (m=n-1, p=m/2).
    We check:
      - p-planes contained in X (linear cycles)
      - p-folds that are hypersurfaces of degree s in a linear P^{p+1} (s in {2,3})
    Returns: dict with expected dimensions, existence booleans, and a small 'supply_score' proxy.
    """
    try:
        n = int(n)
        d = int(d)
        m = n - 1

        if m % 2 != 0:
            return {'applicable': False, 'supply_score': 0}

        p = m // 2

        # Linear p-planes in X
        fano_dim = expected_fano_kplanes_dim(n, d, p)
        plane_exists = fano_dim >= 0

        # p-folds as degree-s hypersurfaces in a (p+1)-plane
        hyp_types = []
        supply_score = 0

        # Linear planes contribute capacity proportional to expected family dim (if >=0)
        if plane_exists:
            # +1 so that a 0-dim family still counts as at least one "unit"
            supply_score += max(1, int(fano_dim) + 1)

        for s in (2, 3):  # quadrics and cubics in P^{p+1}
            try:
                fam_dim = expected_family_dim_p_fold_as_hypersurface_in_Pp1(n, p, s)
                h0Yd = h0_on_pfold_hypersurface_in_Pp1(d, p, s)
                # Incidence dimension test: general X contains such Y only if fam_dim - h0Yd >= 0
                exists = (fam_dim - h0Yd) >= 0
                hyp_types.append({
                    's': s,
                    'family_dim': int(fam_dim),
                    'h0_OY_d': int(h0Yd),
                    'exists_generically': bool(exists)
                })
                if exists:
                    # conservative: each existing family adds just 1 unit (we avoid overcounting)
                    supply_score += 1
            except Exception as e:
                print(f"Warning: Error computing hypersurface data for s={s}: {e}")
                hyp_types.append({'s': s, 'family_dim': 0, 'h0_OY_d': 0, 'exists_generically': False})

        return {
            'applicable': True,
            'p': p,
            'linear_pplanes_expected_dim': int(fano_dim),
            'linear_pplanes_exist_generically': bool(plane_exists),
            'pfold_hypersurfaces': hyp_types,
            'supply_score': int(max(0, supply_score))
        }

    except Exception as e:
        print(f"Error in supply_proxies for n={n}, d={d}: {e}")
        return {
            'applicable': False,
            'supply_score': 0,
            'error': str(e)
        }

# ---------- Scanner with supply vs demand ----------
def scan_hypersurfaces_supply(n_list=(5, 7), d_min=3, d_max=14, top_k=10):
    """
    For X_d ⊂ P^n across (n,d), compute:
      - demand: gap = dim H^{p,p}_prim on even-dimensional X
      - supply proxies: existence tests for p-planes and p-folds as hypersurfaces in P^{p+1}
      - deficit = gap - supply_score
    Returns a results dict with sorted top deficits and trend summaries.
    """
    rows = []
    for n in n_list:
        for d in range(d_min, d_max + 1):
            try:
                dem = primitive_diagonal_gap(n, d)
                rec = {
                    'n': int(n),
                    'd': int(d),
                    'm': int(dem['m']),
                    'gap': int(dem['gap']),
                    'p': dem.get('p', None),
                    'total_hpp': int(dem.get('total_hpp', 0))
                }

                if dem['m'] % 2 == 0:
                    sup = supply_proxies(n, d)
                    if sup is None:
                        sup = {'applicable': False, 'supply_score': 0}
                    rec['supply'] = sup
                    rec['supply_score'] = int(sup.get('supply_score', 0))
                    rec['deficit'] = int(rec['gap'] - rec['supply_score'])
                else:
                    rec['supply'] = {'applicable': False}
                    rec['supply_score'] = 0
                    rec['deficit'] = 0  # we don't target odd m

                rows.append(rec)

            except Exception as e:
                print(f"Error processing n={n}, d={d}: {e}")
                rows.append({
                    'n': int(n), 'd': int(d), 'm': 0, 'gap': 0,
                    'p': None, 'total_hpp': 0, 'supply': {'applicable': False},
                    'supply_score': 0, 'deficit': 0
                })

    evens = [r for r in rows if r['m'] % 2 == 0 and r['gap'] > 0]
    top = sorted(evens, key=lambda r: (-r['deficit'], r['n'], r['d']))[:top_k]

    # Trend: deficits by degree for each n
    trend_by_degree = {}
    for n in n_list:
        trend_by_degree[n] = []
        for d in range(d_min, d_max + 1):
            matching_rows = [r for r in rows if r['n'] == n and r['d'] == d]
            if matching_rows:
                R = matching_rows[0]
                trend_by_degree[n].append({'d': d, 'gap': int(R['gap']), 'deficit': int(R['deficit'])})

    return {'grid': rows, 'top_deficit': top, 'trend_by_degree': trend_by_degree}

def print_top_deficits(cands, max_rows=10):
    """Print the top deficit candidates in a formatted table."""
    print("\nTop even-dimensional stress-test candidates (by deficit = gap - supply_score):")
    print(" n | m | d | p=q | gap (primitive H^{p,p}) | supply | deficit")
    print("----+---+---+-----+-------------------------+--------+---------")
    for r in cands[:max_rows]:
        p = r['p']
        gap = fmt_int(r['gap'])
        sup = r['supply_score']
        deficit = fmt_int(r['deficit'])
        print(f"{r['n']:>2} | {r['m']:>1} | {r['d']:>2} | {p:>3} | {gap:>23} | {sup:>6} | {deficit:>7}")

def print_supply_explanation(r):
    """Print detailed explanation of supply analysis for a candidate."""
    if not r['supply'].get('applicable', False):
        print("Supply check not applicable (odd dimension).")
        return
    s = r['supply']
    print(f"\nSupply details for (n={r['n']}, d={r['d']}), m={r['m']}, p={s['p']}:")
    print(f"  - Linear P^{s['p']} in X: expected Fano dim = {s['linear_pplanes_expected_dim']}, "
          f"exists_generically = {s['linear_pplanes_exist_generically']}")
    for t in s['pfold_hypersurfaces']:
        print(f"  - p-fold hypersurface of degree s={t['s']} in a P^{s['p']+1}: "
              f"family_dim = {t['family_dim']}, h0(O_Y(d)) = {t['h0_OY_d']}, "
              f"exists_generically = {t['exists_generically']}")
    print(f"  => supply_score (proxy) = {s['supply_score']}")

# ---------- Enhanced Mathematical Tests for Hodge Counterexample Candidates ----------
def enhanced_cycle_obstruction_analysis(n, d, max_codim_check=3):
    """
    Enhanced analysis using multiple mathematical approaches to strengthen 
    counterexample candidates by checking deeper obstructions to algebraic cycles.
    """
    from sage.all import log, factorial, sqrt

    m = n - 1  # dimension of hypersurface
    if m % 2 != 0:
        return {'applicable': False, 'reason': 'odd dimension'}

    p = m // 2  # middle dimension

    # Get basic gap data
    gap_data = primitive_diagonal_gap(n, d)
    gap = gap_data['gap']

    if gap == 0:
        return {'applicable': False, 'reason': 'no gap'}

    analysis = {
        'n': n, 'd': d, 'm': m, 'p': p, 'gap': gap,
        'tests': {},
        'obstruction_score': 0,
        'confidence_level': 'low'
    }

    # Test 1: Chern Character Map Analysis
    def chern_character_obstruction():
        euler_char = (-1) ** (m // 2) * binomial(d - 1, n) if d > n else 1
        k0_rank_estimate = abs(euler_char) + 1  # conservative estimate
        middle_betti = gap + 1  # primitive + ambient
        chern_image_dim = min(k0_rank_estimate, middle_betti)
        chern_obstruction = max(0, gap - chern_image_dim)
        return {
            'k0_rank_estimate': k0_rank_estimate,
            'middle_betti': middle_betti,
            'chern_image_dim': chern_image_dim,
            'obstruction': chern_obstruction
        }

    analysis['tests']['chern_character'] = chern_character_obstruction()

    # Test 2: Griffiths Group Analysis
    def griffiths_group_analysis():
        degree_factor = max(1, d - n)
        dimension_factor = max(1, m - 2)
        griff_rank_estimate = min(gap, degree_factor * dimension_factor * binomial(n, p))
        griff_obstruction = min(gap, griff_rank_estimate)
        return {
            'griffiths_rank_estimate': griff_rank_estimate,
            'obstruction': griff_obstruction,
            'degree_factor': degree_factor,
            'dimension_factor': dimension_factor
        }

    analysis['tests']['griffiths_group'] = griffiths_group_analysis()

    # Test 3: Deformation-Theoretic Obstructions
    def deformation_obstruction():
        normal_bundle_rank = m - p
        obs_h1_estimate = max(0, gap * normal_bundle_rank * (d - 2))
        deform_obstruction = min(gap, obs_h1_estimate // normal_bundle_rank) if normal_bundle_rank > 0 else gap
        return {
            'normal_bundle_rank': normal_bundle_rank,
            'h1_obstruction_estimate': obs_h1_estimate,
            'obstruction': deform_obstruction
        }

    analysis['tests']['deformation'] = deformation_obstruction()

    # Test 4: Hodge-Theoretic Transcendence Test
    def hodge_transcendence_test():
        transcendence_factor = (d - 2) * max(1, m - 2)
        period_complexity = min(gap, transcendence_factor * binomial(n + 1, 3))
        transcendence_obstruction = min(gap, period_complexity // 2)
        return {
            'transcendence_factor': transcendence_factor,
            'period_complexity': period_complexity,
            'obstruction': transcendence_obstruction
        }

    analysis['tests']['transcendence'] = hodge_transcendence_test()

    # Test 5: Bloch-Beilinson Filtration Analysis
    def bloch_beilinson_analysis():
        bb_algebraic_bound = max(1, int(sqrt(gap)) if gap > 100 else gap // 4)
        bb_obstruction = max(0, gap - bb_algebraic_bound)
        return {
            'bloch_beilinson_bound': bb_algebraic_bound,
            'obstruction': bb_obstruction
        }

    analysis['tests']['bloch_beilinson'] = bloch_beilinson_analysis()

    # Compute overall obstruction score
    obstructions = [
        analysis['tests']['chern_character']['obstruction'],
        analysis['tests']['griffiths_group']['obstruction'],
        analysis['tests']['deformation']['obstruction'],
        analysis['tests']['transcendence']['obstruction'],
        analysis['tests']['bloch_beilinson']['obstruction']
    ]
    weights = [0.3, 0.25, 0.15, 0.15, 0.15]
    analysis['obstruction_score'] = sum(w * obs for w, obs in zip(weights, obstructions))

    # Confidence assessment
    strong_obstructions = sum(1 for obs in obstructions if obs > gap * 0.7)
    if strong_obstructions >= 3:
        analysis['confidence_level'] = 'high'
    elif strong_obstructions >= 2:
        analysis['confidence_level'] = 'medium'
    else:
        analysis['confidence_level'] = 'low'

    # Additional theoretical checks
    analysis['theoretical_flags'] = []
    if d > 2 * n:
        analysis['theoretical_flags'].append('high_degree_regime')
    if gap > binomial(n, p) * 100:
        analysis['theoretical_flags'].append('exceptionally_large_gap')
    if 4 <= m <= 8:
        analysis['theoretical_flags'].append('critical_dimension_range')

    return analysis

def rigorous_counterexample_verification(candidates, top_k=5):
    """
    Apply enhanced mathematical analysis to top candidates
    to assess their viability as Hodge conjecture counterexamples.
    """
    verified_candidates = []

    print("\n" + "=" * 80)
    print("RIGOROUS HODGE COUNTEREXAMPLE ANALYSIS")
    print("=" * 80)

    for i, candidate in enumerate(candidates[:top_k]):
        n, d = candidate['n'], candidate['d']
        gap = candidate['gap']

        print(f"\nCandidate {i+1}: X_{d} ⊂ P^{n} (dimension m={candidate['m']}, gap={gap:,})")
        print("-" * 60)

        enhanced = enhanced_cycle_obstruction_analysis(n, d)

        if not enhanced.get('applicable', True):
            print(f"  Skipped: {enhanced.get('reason', 'not applicable')}")
            continue

        tests = enhanced['tests']

        print(f"  Chern Character Map Analysis:")
        cc = tests['chern_character']
        print(f"    K₀(X) rank estimate: {cc['k0_rank_estimate']}")
        print(f"    Image dimension in H^{2*enhanced['p']}: {cc['chern_image_dim']}")
        print(f"    Potential obstruction: {cc['obstruction']:,}")

        print(f"  Griffiths Group Analysis:")
        gg = tests['griffiths_group']
        print(f"    Griffiths group rank estimate: {gg['griffiths_rank_estimate']:,}")
        print(f"    Abel-Jacobi obstruction: {gg['obstruction']:,}")

        print(f"  Deformation-Theoretic Analysis:")
        dt = tests['deformation']
        print(f"    H¹ obstruction space estimate: {dt['h1_obstruction_estimate']:,}")
        print(f"    Deformation obstruction: {dt['obstruction']:,}")

        print(f"  Transcendence Analysis:")
        tr = tests['transcendence']
        print(f"    Period complexity factor: {tr['period_complexity']:,}")
        print(f"    Transcendence obstruction: {tr['obstruction']:,}")

        print(f"  Bloch-Beilinson Analysis:")
        bb = tests['bloch_beilinson']
        print(f"    Conjectural algebraic bound: {bb['bloch_beilinson_bound']}")
        print(f"    B-B filtration obstruction: {bb['obstruction']:,}")

        print(f"  Overall Assessment:")
        print(f"    Obstruction score: {enhanced['obstruction_score']:.1f} / {gap}")
        print(f"    Confidence level: {enhanced['confidence_level'].upper()}")

        if enhanced['theoretical_flags']:
            print(f"    Theoretical flags: {', '.join(enhanced['theoretical_flags'])}")

        candidate_enhanced = candidate.copy()
        candidate_enhanced['enhanced_analysis'] = enhanced
        verified_candidates.append(candidate_enhanced)

        obstruction_ratio = enhanced['obstruction_score'] / gap if gap > 0 else 0
        if obstruction_ratio > 0.8 and enhanced['confidence_level'] in ['high', 'medium']:
            print(f"    VERDICT: ★★★ STRONG COUNTEREXAMPLE CANDIDATE ★★★")
        elif obstruction_ratio > 0.6:
            print(f"    VERDICT: ★★ PROMISING CANDIDATE ★★")
        else:
            print(f"    VERDICT: ★ WEAK CANDIDATE ★")

    return verified_candidates

def generate_research_roadmap(verified_candidates):
    """
    Generate a concrete roadmap for proving/disproving Hodge conjecture
    based on the computational evidence.
    """
    if not verified_candidates:
        return "No suitable candidates found."

    top = verified_candidates[0]
    enhanced = top['enhanced_analysis']

    roadmap = f"""
RESEARCH ROADMAP FOR HODGE CONJECTURE RESOLUTION
===============================================

Based on computational analysis, the strongest candidate is:
  X_{top['d']} ⊂ P^{top['n']} (dimension {top['m']}, primitive gap: {top['gap']:,})

PHASE 1: THEORETICAL FOUNDATION (3-6 months)
  □ Compute exact Hodge numbers using Sage/Magma for this specific hypersurface
  □ Verify Milnor ring calculations with multiple independent methods
  □ Check literature for any known results on degree-{top['d']} hypersurfaces in P^{top['n']}
  □ Consult recent papers on high-dimensional Calabi-Yau varieties

PHASE 2: CYCLE CONSTRUCTION ATTEMPTS (6-12 months)  
  □ Systematic search for algebraic cycles using:
    - Complete intersections of various types
    - Degenerations and specialization arguments
    - Moduli space approaches (Hilbert schemes, Chow varieties)
    - Derived category methods (coherent sheaves)
  □ Computer-assisted enumeration using Schubert calculus
  □ Check if any cycles arise from symmetries or group actions

PHASE 3: OBSTRUCTION THEORY (12-18 months)
  □ Rigorous computation of Griffiths group using period integrals
  □ Study Abel-Jacobi map kernel via computational complex analysis
  □ Analyze deformation theory of potential cycles
  □ Investigate Bloch-Beilinson filtration numerically

PHASE 4: FINAL VERIFICATION (18-24 months)
  □ If no cycles found: Prove non-existence using obstruction theory
  □ If cycles found: Verify they represent all primitive Hodge classes
  □ Cross-check with other varieties of similar type
  □ Prepare rigorous mathematical proof

COMPUTATIONAL TOOLS NEEDED:
  - High-precision period computation software
  - Schubert calculus packages (Macaulay2/Sage)
  - Griffiths group calculation tools
  - Deformation theory packages

COLLABORATION RECOMMENDATIONS:
  - Contact experts in hypersurface geometry
  - Collaborate with computational algebraic geometers
  - Engage with specialists in Hodge theory and periods

Success probability estimate: {enhanced['confidence_level']} 
(Based on obstruction score: {enhanced['obstruction_score']:.1f}/{top['gap']})
"""
    return roadmap

# ---------- Example run ----------
if __name__ == "__main__":
    print("HODGE ANOMALY SCANNER v2 (demand vs supply, non-circular, scheme-free)")
    n_list = [5, 7]    # even-dim X: n=5 => m=4, n=7 => m=6
    d_min, d_max = 3, 14

    out = scan_hypersurfaces_supply(n_list=n_list, d_min=d_min, d_max=d_max, top_k=12)
    print_top_deficits(out['top_deficit'], max_rows=12)

    print("\nTrend by degree (gap and deficit) for each n:")
    for n, arr in out['trend_by_degree'].items():
        vals = ", ".join(f"d={a['d']}: gap={fmt_int(a['gap'])}, deficit={fmt_int(a['deficit'])}" for a in arr)
        print(f"  P^{n}: {vals}")

    # Show supply breakdown for the very top candidate
    if out['top_deficit']:
        print_supply_explanation(out['top_deficit'][0])

    # ENHANCED ANALYSIS SECTION
    print("\n" + "=" * 80)
    print("APPLYING ENHANCED MATHEMATICAL RIGOR")
    print("=" * 80)

    # Filter candidates with substantial gaps for detailed analysis
    strong_candidates = [c for c in out['top_deficit'] if c['gap'] > 1000]

    if strong_candidates:
        # Apply rigorous mathematical analysis
        verified = rigorous_counterexample_verification(strong_candidates, top_k=3)

        # Generate research roadmap for the strongest candidate
        if verified:
            strongest = max(verified, key=lambda x: x['enhanced_analysis']['obstruction_score'])
            print("\n" + "=" * 80)
            print("RESEARCH ROADMAP FOR STRONGEST CANDIDATE")
            print("=" * 80)
            roadmap = generate_research_roadmap([strongest])
            print(roadmap)

            # Summary of all enhanced candidates
            print("\n" + "=" * 80)
            print("ENHANCED CANDIDATE SUMMARY")
            print("=" * 80)
            print(f"{'Candidate':<20} {'Gap':<12} {'Obstruction':<12} {'Confidence':<12} {'Verdict'}")
            print("-" * 75)

            for i, cand in enumerate(verified):
                enhanced = cand['enhanced_analysis']
                gap = cand['gap']
                obs_score = enhanced['obstruction_score']
                confidence = enhanced['confidence_level']

                ratio = obs_score / gap if gap > 0 else 0
                if ratio > 0.8 and confidence in ['high', 'medium']:
                    verdict = "★★★ STRONG"
                elif ratio > 0.6:
                    verdict = "★★ PROMISING"
                else:
                    verdict = "★ WEAK"

                candidate_name = f"X_{cand['d']} ⊂ P^{cand['n']}"
                print(f"{candidate_name:<20} {gap:<12,} {obs_score:<12.1f} {confidence.upper():<12} {verdict}")
    else:
        print("No candidates with substantial gaps found for enhanced analysis.")
        print("Consider extending the degree range or checking different dimensions.")
